{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height has been deprecated.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ljj/anaconda/envs/python3env/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    " \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.externals import joblib \n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMRegressor\n",
    "import math\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_colwidth',1000)\n",
    "pd.set_option('display.height',1000)\n",
    "pd.set_option('display.max_rows',500)\n",
    "pd.set_option('display.max_columns',500)\n",
    "pd.set_option('display.width',1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./public.train.csv')\n",
    "test_data = pd.read_csv('./public.test.csv')\n",
    "\n",
    "df_result = pd.DataFrame()\n",
    "df_result['ID'] = list(test_data['ID'])\n",
    "special_missing_ID = test_data[test_data[(test_data == 0) | (test_data == 0.)].count(axis=1) > 13]['ID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 异常值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = pd.concat([train_data, test_data], axis=0).sort_values(by='ID').reset_index().drop(['index'], axis=1)\n",
    "bad_feature = ['ID', '功率A', '功率B', '功率C', '平均功率', '现场温度', '电压A', '电压B', '电压C', '电流B', '电流C', '转换效率', '转换效率A', '转换效率B', '转换效率C']\n",
    "bad_index = all_data[bad_feature][\n",
    "    (all_data[bad_feature] > all_data[bad_feature].mean() + 2 * all_data[bad_feature].std()) | \n",
    "    (all_data[bad_feature] < all_data[bad_feature].mean() - 2 * all_data[bad_feature].std())\n",
    "].dropna(how='all').index\n",
    "\n",
    "nn_bad_data = all_data.loc[np.concatenate([bad_index - 1, bad_index, bad_index + 1])].sort_values(by='ID', ascending=True).drop_duplicates()\n",
    "bad_data = all_data.loc[bad_index].sort_values(by='ID', ascending=True)\n",
    "len(bad_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 上下记录均值替代异常值\n",
    "for idx, line in bad_data.iterrows():\n",
    "    ID = line['ID']\n",
    "    col_index = line[bad_feature][ \n",
    "        (line[bad_feature] > all_data[bad_feature].mean() + 2 * all_data[bad_feature].std())| \n",
    "        (line[bad_feature] < all_data[bad_feature].mean() - 2 * all_data[bad_feature].std())\n",
    "    ].index\n",
    "    index = all_data[all_data['ID'] == ID].index\n",
    "    \n",
    "    before_offset = 1\n",
    "    while (idx + before_offset)in bad_index:\n",
    "        before_offset += 1\n",
    "\n",
    "    after_offset = 1\n",
    "    while (idx + after_offset) in bad_index:\n",
    "        after_offset += 1\n",
    "    \n",
    "    replace_value = (all_data.loc[index - before_offset, col_index].values + all_data.loc[index + after_offset, col_index].values) / 2\n",
    "    all_data.loc[index, col_index] = replace_value[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 拆分数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9000, 8409)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = all_data.drop(all_data[all_data['ID'].isin(df_result['ID'])].index).reset_index().drop(['index'], axis=1)\n",
    "test_data = all_data[all_data['ID'].isin(df_result['ID'])].drop(['发电量'], axis=1).reset_index().drop(['index'], axis=1)\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 去除重复值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dup_train_data = train_data.drop_duplicates(train_data.columns.drop('ID'), keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_train_data(train_data, test_data, poly=False, select=False):\n",
    "    y = train_data['发电量']\n",
    "    X = train_data.drop(['发电量','ID'], axis=1)\n",
    "    sub_data = test_data.drop(['ID'], axis=1)\n",
    "\n",
    "    if poly:\n",
    "        from sklearn.preprocessing import PolynomialFeatures\n",
    "        poly = PolynomialFeatures(degree=2, interaction_only=True)\n",
    "        X = poly.fit_transform(X)\n",
    "        sub_data = poly.transform(sub_data)\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "    if select:\n",
    "        from sklearn.feature_selection import SelectFromModel\n",
    "        sm = SelectFromModel(GradientBoostingRegressor(random_state=2))\n",
    "        X_train = sm.fit_transform(X_train, y_train)\n",
    "        X_test = sm.transform(X_test)\n",
    "        sub_data = sm.transform(sub_data)\n",
    "        \n",
    "    return X_train, X_test, y_train, y_test, sub_data\n",
    "\n",
    "def cal_score(mse):\n",
    "    if isinstance(mse, float):\n",
    "        return 1 / (1 + math.sqrt(mse))\n",
    "    else:\n",
    "        return np.divide(1, 1 + np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, sub_data = generate_train_data(dup_train_data, test_data, poly=True, select=True)\n",
    "cX_train, cX_test, cy_train, cy_test, _ = generate_train_data(train_data, test_data, poly=True, select=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# xgbt = xgb.XGBRegressor(n_estimators=300, max_depth=3, random_state=2, n_jobs=8)\n",
    "# gbdt = GradientBoostingRegressor(n_estimators=300, max_depth=3, max_features='log2', random_state=2)\n",
    "# forest = RandomForestRegressor(n_estimators=100, max_features='log2', random_state=2, n_jobs=8)\n",
    "\n",
    "# lgb_params = {}\n",
    "# lgb_params['n_estimators'] = 300\n",
    "# lgb_params['max_depth'] = 3 \n",
    "# lgb_params['random_state'] = 2\n",
    "# lgb = LGBMRegressor(**lgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def train(X_train, y_train):\n",
    "#     xgbt.fit(X_train, y_train)\n",
    "#     gbdt.fit(X_train, y_train)\n",
    "#     forest.fit(X_train, y_train)\n",
    "#     lgb.fit(X_train, y_train)\n",
    "\n",
    "# def predict(X_test, y_test):\n",
    "#     y_pred_xgb = xgbt.predict(X_test)\n",
    "#     mse_xgb = mean_squared_error(y_test.values, y_pred_xgb)\n",
    "    \n",
    "#     y_pred_gbdt = gbdt.predict(X_test)\n",
    "#     mse_gbdt = mean_squared_error(y_test.values, y_pred_gbdt)\n",
    "    \n",
    "#     y_pred_forest = forest.predict(X_test)\n",
    "#     mse_forest = mean_squared_error(y_true=y_test, y_pred=y_pred_forest)\n",
    "    \n",
    "#     y_pred_lgb = lgb.predict(X_test)\n",
    "#     mse_lgb = mean_squared_error(y_true=y_test, y_pred=y_pred_lgb)\n",
    "    \n",
    "#     res = pd.DataFrame()\n",
    "#     res['model'] = np.array(['XGBoost', 'Sklearn_GBDT', 'RandomForest', 'LightGBM'])\n",
    "#     res['mse'] = np.array([mse_xgb, mse_gbdt, mse_forest, mse_lgb])\n",
    "#     res['score'] = np.array([cal_score(mse_xgb), cal_score(mse_gbdt), cal_score(mse_forest), cal_score(mse_lgb)])\n",
    "#     return res\n",
    "\n",
    "# def cross_validation_using_mse(X_train, y_train, cv=5):    \n",
    "#     scores_xgb = cross_val_score(xgbt, X_train, y_train, cv=cv, scoring='neg_mean_squared_error')\n",
    "#     xgb_avg = np.average(-scores_xgb)\n",
    "#     print('Average XGB - MSE:', xgb_avg, ' - Score:', cal_score(-scores_xgb).mean())\n",
    "    \n",
    "#     scores_gbdt = cross_val_score(gbdt, X_train, y_train, cv=cv, scoring='neg_mean_squared_error')\n",
    "#     gbdt_avg = np.average(-scores_gbdt)\n",
    "#     print('Average GBDT - MSE:', gbdt_avg, ' - Score:', cal_score(-scores_gbdt).mean())\n",
    "    \n",
    "#     scores_forest = cross_val_score(forest, X_train, y_train, cv=cv, scoring='neg_mean_squared_error')\n",
    "#     rf_avg = np.average(-scores_forest)\n",
    "#     print('Average RF - MSE:', rf_avg, ' - Score:', cal_score(-scores_forest).mean())\n",
    "    \n",
    "#     scores_lgb = cross_val_score(lgb, X_train, y_train, cv=cv, scoring='neg_mean_squared_error')\n",
    "#     lgb_avg = np.average(-scores_lgb)\n",
    "#     print('Average LGB - MSE:', lgb_avg, ' - Score:', cal_score(-scores_lgb).mean())\n",
    "    \n",
    "#     res = pd.DataFrame({\n",
    "#         'XGBoost': -scores_xgb,\n",
    "#         'Sklearn_GBDT': -scores_gbdt,\n",
    "#         'RandomForest': -scores_forest,\n",
    "#         'LightGBM': -scores_lgb\n",
    "#     })\n",
    "    \n",
    "#     return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(X_train, y_train)\n",
    "# predict(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_validation_using_mse(np.concatenate([X_train, X_test]), np.concatenate([y_train, y_test]), cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_X_train = np.concatenate([X_train, X_test])\n",
    "all_y_train = np.concatenate([y_train, y_test])\n",
    "c_all_X_train = np.concatenate([cX_train, cX_test])\n",
    "c_all_y_train = np.concatenate([cy_train, cy_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgbt1 = xgb.XGBRegressor(n_estimators=300, max_depth=3, random_state=2, n_jobs=8)\n",
    "gbdt1 = GradientBoostingRegressor(n_estimators=300, max_depth=3, max_features='log2', random_state=2)\n",
    "forest1 = RandomForestRegressor(n_estimators=100, max_features='log2', random_state=2, n_jobs=8)\n",
    "lgb1 = LGBMRegressor(n_estimators=300, max_depth=3, random_state=2)\n",
    "\n",
    "xgbt2 = xgb.XGBRegressor(n_estimators=200, random_state=3, n_jobs=8)\n",
    "gbdt2 = GradientBoostingRegressor(n_estimators=200, max_features='sqrt', random_state=3)\n",
    "forest2 = RandomForestRegressor(n_estimators=70, max_features='sqrt', random_state=3)\n",
    "lgb2 = LGBMRegressor(n_estimators=200, random_state=3, n_jobs=8)\n",
    "\n",
    "xgbt3 = xgb.XGBRegressor(n_estimators=300, random_state=4, n_jobs=8)\n",
    "gbdt3 = GradientBoostingRegressor(n_estimators=300, max_features='sqrt', random_state=4)\n",
    "forest3 = RandomForestRegressor(n_estimators=150, max_features='sqrt', random_state=4)\n",
    "lgb3 = LGBMRegressor(n_estimators=300, random_state=4, n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "       importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "       min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "       n_estimators=300, n_jobs=8, num_leaves=31, objective=None,\n",
       "       random_state=4, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbt1.fit(all_X_train, all_y_train)\n",
    "gbdt1.fit(all_X_train, all_y_train)\n",
    "forest1.fit(all_X_train, all_y_train)\n",
    "lgb1.fit(all_X_train, all_y_train)\n",
    "\n",
    "xgbt2.fit(all_X_train, all_y_train)\n",
    "gbdt2.fit(all_X_train, all_y_train)\n",
    "forest2.fit(all_X_train, all_y_train)\n",
    "lgb2.fit(all_X_train, all_y_train)\n",
    "\n",
    "xgbt3.fit(c_all_X_train, c_all_y_train)\n",
    "gbdt3.fit(c_all_X_train, c_all_y_train)\n",
    "forest3.fit(c_all_X_train, c_all_y_train)\n",
    "lgb3.fit(c_all_X_train, c_all_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01810329 0.03928285 0.02364234 0.08030995 0.06919055]\n",
      "Average XGB - MSE: 0.04610579580055509  - Score: [0.88140791 0.8345859  0.86673088 0.77918631 0.79173996] \n",
      "\n",
      "[0.01837326 0.04046206 0.02395528 0.07912045 0.07069063]\n",
      "Average XGB - MSE: 0.046520336191521135  - Score: [0.8806321  0.83253421 0.86596961 0.78046735 0.7899661 ] \n",
      "\n",
      "[0.03026044 0.03426352 0.03241173 0.05745061 0.10457821]\n",
      "Average XGB - MSE: 0.05179290201015561  - Score: [0.85182121 0.84380775 0.84743423 0.8066542  0.75563769]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn1 = KNeighborsRegressor(n_neighbors=5)\n",
    "knn1.fit(all_X_train, all_y_train)\n",
    "scores_knn = cross_val_score(knn1, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "print(-scores_knn)\n",
    "knn_avg = np.average(-scores_knn)\n",
    "print('Average XGB - MSE:', knn_avg, ' - Score:', cal_score(-scores_knn), '\\n')\n",
    "\n",
    "knn2 = KNeighborsRegressor(n_neighbors=4)\n",
    "knn2.fit(all_X_train, all_y_train)\n",
    "scores_knn2 = cross_val_score(knn2, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "print(-scores_knn2)\n",
    "knn_avg2 = np.average(-scores_knn2)\n",
    "print('Average XGB - MSE:', knn_avg2, ' - Score:', cal_score(-scores_knn2), '\\n')\n",
    "\n",
    "knn3 = KNeighborsRegressor(n_neighbors=4)\n",
    "knn3.fit(c_all_X_train, c_all_y_train)\n",
    "scores_knn3 = cross_val_score(knn3, cX_train, cy_train, cv=5, scoring='neg_mean_squared_error')\n",
    "print(-scores_knn3)\n",
    "knn_avg3 = np.average(-scores_knn3)\n",
    "print('Average XGB - MSE:', knn_avg3, ' - Score:', cal_score(-scores_knn3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# regrs = [\n",
    "#     xgbt1, xgbt2, xgbt3,\n",
    "#     gbdt1, gbdt2, gbdt3,\n",
    "#     forest1, forest2, forest3,\n",
    "#     knn1, knn2, knn3\n",
    "# ]\n",
    "regrs = [\n",
    "    xgbt1, gbdt1, forest1, lgb1, knn1, \n",
    "    xgbt2, gbdt2, forest2, lgb2, knn2, \n",
    "    xgbt3, gbdt3, forest3, lgb3, knn3\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Stacker(object):\n",
    "    def __init__(self, n_splits, stacker, base_models):\n",
    "        self.n_splits = n_splits\n",
    "        self.stacker = stacker\n",
    "        self.base_models = base_models\n",
    "    \n",
    "    # X: 原始训练集, y: 原始训练集真实值, predict_data: 原始待预测数据\n",
    "    def fit_predict(self, X, y, predict_data):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        T = np.array(predict_data)\n",
    "\n",
    "        folds = list(KFold(n_splits=self.n_splits, shuffle=False, random_state=2018).split(X, y))\n",
    "        \n",
    "        # 以基学习器预测结果为特征的 stacker的训练数据 与 stacker预测数据\n",
    "        S_train = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        S_predict = np.zeros((predict_data.shape[0], len(self.base_models)))\n",
    "        \n",
    "        for i, regr in enumerate(self.base_models):\n",
    "            print(i + 1, 'Base model:', str(regr).split('(')[0])\n",
    "            S_predict_i = np.zeros((predict_data.shape[0], self.n_splits))\n",
    "            \n",
    "            for j, (train_idx, test_idx) in enumerate(folds):\n",
    "                # 将X分为训练集与测试集\n",
    "                X_train, y_train, X_test, y_test = X[train_idx], y[train_idx], X[test_idx], y[test_idx]\n",
    "                print ('Fit fold', (j+1), '...')\n",
    "                regr.fit(X_train, y_train)\n",
    "                y_pred = regr.predict(X_test)                \n",
    "                S_train[test_idx, i] = y_pred\n",
    "                S_predict_i[:, j] = regr.predict(T)\n",
    "            \n",
    "            S_predict[:, i] = S_predict_i.mean(axis=1)\n",
    "\n",
    "        nmse_score = cross_val_score(self.stacker, S_train, y, cv=5, scoring='neg_mean_squared_error')\n",
    "        print('CV MSE:', -nmse_score)\n",
    "        print('Stacker AVG MSE:', -nmse_score.mean(), 'Stacker AVG Score:', np.mean(np.divide(1, 1 + np.sqrt(-nmse_score))))\n",
    "\n",
    "        self.stacker.fit(S_train, y)\n",
    "        res = self.stacker.predict(S_predict)\n",
    "        return res, S_train, S_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stacking_model = Ridge(alpha=0.387, copy_X=True, fit_intercept=False, solver='auto', random_state=2)\n",
    "stacker = Stacker(5, stacking_model, regrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Base model: XGBRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "2 Base model: GradientBoostingRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "3 Base model: RandomForestRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "4 Base model: LGBMRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "5 Base model: KNeighborsRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "6 Base model: XGBRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "7 Base model: GradientBoostingRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "8 Base model: RandomForestRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "9 Base model: LGBMRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "10 Base model: KNeighborsRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "11 Base model: XGBRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "12 Base model: GradientBoostingRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "13 Base model: RandomForestRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "14 Base model: LGBMRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "15 Base model: KNeighborsRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "CV MSE: [0.00950528 0.01956392 0.00994718 0.08386419 0.01414895]\n",
      "Stacker AVG MSE: 0.027405904150192784 Stacker AVG Score: 0.8733802862200604\n"
     ]
    }
   ],
   "source": [
    "pred_stack, S_train_data, S_predict_data = stacker.fit_predict(all_X_train, all_y_train, sub_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_result['score'] = pred_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>940</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>1694</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>1879</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>2823</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427</th>\n",
       "      <td>3202</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>4459</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068</th>\n",
       "      <td>4648</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>4821</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2217</th>\n",
       "      <td>5010</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2218</th>\n",
       "      <td>5013</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2240</th>\n",
       "      <td>5074</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2241</th>\n",
       "      <td>5077</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2335</th>\n",
       "      <td>5281</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2336</th>\n",
       "      <td>5292</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2419</th>\n",
       "      <td>5508</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2617</th>\n",
       "      <td>5911</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>6121</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2906</th>\n",
       "      <td>6531</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2907</th>\n",
       "      <td>6534</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3652</th>\n",
       "      <td>8146</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3705</th>\n",
       "      <td>8245</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3741</th>\n",
       "      <td>8310</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3831</th>\n",
       "      <td>8488</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4122</th>\n",
       "      <td>9088</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4223</th>\n",
       "      <td>9296</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4335</th>\n",
       "      <td>9505</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4426</th>\n",
       "      <td>9719</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4505</th>\n",
       "      <td>9916</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>10124</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4708</th>\n",
       "      <td>10335</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4906</th>\n",
       "      <td>10736</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5016</th>\n",
       "      <td>10917</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5127</th>\n",
       "      <td>11119</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5536</th>\n",
       "      <td>11963</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6435</th>\n",
       "      <td>13830</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6529</th>\n",
       "      <td>14032</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6636</th>\n",
       "      <td>14243</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6744</th>\n",
       "      <td>14457</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7167</th>\n",
       "      <td>15299</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7254</th>\n",
       "      <td>15508</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7562</th>\n",
       "      <td>16144</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7666</th>\n",
       "      <td>16348</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7942</th>\n",
       "      <td>16925</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8146</th>\n",
       "      <td>17342</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8242</th>\n",
       "      <td>17527</td>\n",
       "      <td>0.379993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID     score\n",
       "0         1  0.379993\n",
       "425     940  0.379993\n",
       "754    1694  0.379993\n",
       "841    1879  0.379993\n",
       "1276   2823  0.379993\n",
       "1427   3202  0.379993\n",
       "1979   4459  0.379993\n",
       "2068   4648  0.379993\n",
       "2139   4821  0.379993\n",
       "2217   5010  0.379993\n",
       "2218   5013  0.379993\n",
       "2240   5074  0.379993\n",
       "2241   5077  0.379993\n",
       "2335   5281  0.379993\n",
       "2336   5292  0.379993\n",
       "2419   5508  0.379993\n",
       "2617   5911  0.379993\n",
       "2706   6121  0.379993\n",
       "2906   6531  0.379993\n",
       "2907   6534  0.379993\n",
       "3652   8146  0.379993\n",
       "3705   8245  0.379993\n",
       "3741   8310  0.379993\n",
       "3831   8488  0.379993\n",
       "4122   9088  0.379993\n",
       "4223   9296  0.379993\n",
       "4335   9505  0.379993\n",
       "4426   9719  0.379993\n",
       "4505   9916  0.379993\n",
       "4603  10124  0.379993\n",
       "4708  10335  0.379993\n",
       "4906  10736  0.379993\n",
       "5016  10917  0.379993\n",
       "5127  11119  0.379993\n",
       "5536  11963  0.379993\n",
       "6435  13830  0.379993\n",
       "6529  14032  0.379993\n",
       "6636  14243  0.379993\n",
       "6744  14457  0.379993\n",
       "7167  15299  0.379993\n",
       "7254  15508  0.379993\n",
       "7562  16144  0.379993\n",
       "7666  16348  0.379993\n",
       "7942  16925  0.379993\n",
       "8146  17342  0.379993\n",
       "8242  17527  0.379993"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = df_result[df_result['ID'].isin(special_missing_ID)].index\n",
    "df_result.loc[index, 'score'] = 0.379993053\n",
    "df_result[df_result['ID'].isin(special_missing_ID)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_result.to_csv('submit_stack_15_poly_select_dropdup_outlier_test3.csv', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
