{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ljj/anaconda/envs/python3env/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height has been deprecated.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    " \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.externals import joblib \n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMRegressor\n",
    "import math\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_colwidth',1000)\n",
    "pd.set_option('display.height',1000)\n",
    "pd.set_option('display.max_rows',500)\n",
    "pd.set_option('display.max_columns',500)\n",
    "pd.set_option('display.width',1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./public.train.csv')\n",
    "test_data = pd.read_csv('./public.test.csv')\n",
    "\n",
    "df_result = pd.DataFrame()\n",
    "df_result['ID'] = list(test_data['ID'])\n",
    "special_missing_ID = test_data[test_data[(test_data == 0) | (test_data == 0.)].count(axis=1) > 13]['ID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 异常值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = pd.concat([train_data, test_data], axis=0).sort_values(by='ID').reset_index().drop(['index'], axis=1)\n",
    "bad_feature = ['ID', '功率A', '功率B', '功率C', '平均功率', '现场温度', '电压A', '电压B', '电压C', '电流B', '电流C', '转换效率', '转换效率A', '转换效率B', '转换效率C']\n",
    "bad_index = all_data[bad_feature][\n",
    "    (all_data[bad_feature] > all_data[bad_feature].mean() + 2 * all_data[bad_feature].std()) | \n",
    "    (all_data[bad_feature] < all_data[bad_feature].mean() - 2 * all_data[bad_feature].std())\n",
    "].dropna(how='all').index\n",
    "\n",
    "nn_bad_data = all_data.loc[np.concatenate([bad_index - 1, bad_index, bad_index + 1])].sort_values(by='ID', ascending=True).drop_duplicates()\n",
    "bad_data = all_data.loc[bad_index].sort_values(by='ID', ascending=True)\n",
    "len(bad_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 上下记录均值替代异常值\n",
    "for idx, line in bad_data.iterrows():\n",
    "    ID = line['ID']\n",
    "    col_index = line[bad_feature][ \n",
    "        (line[bad_feature] > all_data[bad_feature].mean() + 2 * all_data[bad_feature].std())| \n",
    "        (line[bad_feature] < all_data[bad_feature].mean() - 2 * all_data[bad_feature].std())\n",
    "    ].index\n",
    "    index = all_data[all_data['ID'] == ID].index\n",
    "    \n",
    "    before_offset = 1\n",
    "    while (idx + before_offset)in bad_index:\n",
    "        before_offset += 1\n",
    "\n",
    "    after_offset = 1\n",
    "    while (idx + after_offset) in bad_index:\n",
    "        after_offset += 1\n",
    "    \n",
    "    replace_value = (all_data.loc[index - before_offset, col_index].values + all_data.loc[index + after_offset, col_index].values) / 2\n",
    "    all_data.loc[index, col_index] = replace_value[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 拆分数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9000, 8409)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = all_data.drop(all_data[all_data['ID'].isin(df_result['ID'])].index).reset_index().drop(['index'], axis=1)\n",
    "test_data = all_data[all_data['ID'].isin(df_result['ID'])].drop(['发电量'], axis=1).reset_index().drop(['index'], axis=1)\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 去除重复值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dup_train_data = train_data.drop_duplicates(train_data.columns.drop('ID'), keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_train_data(train_data, test_data, poly=False, select=False):\n",
    "    y = train_data['发电量']\n",
    "    X = train_data.drop(['发电量','ID'], axis=1)\n",
    "    sub_data = test_data.drop(['ID'], axis=1)\n",
    "\n",
    "    if poly:\n",
    "        from sklearn.preprocessing import PolynomialFeatures\n",
    "        poly = PolynomialFeatures(degree=2, interaction_only=True)\n",
    "        X = poly.fit_transform(X)\n",
    "        sub_data = poly.transform(sub_data)\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "    if select:\n",
    "        from sklearn.feature_selection import SelectFromModel\n",
    "        sm = SelectFromModel(GradientBoostingRegressor(random_state=2))\n",
    "        X_train = sm.fit_transform(X_train, y_train)\n",
    "        X_test = sm.transform(X_test)\n",
    "        sub_data = sm.transform(sub_data)\n",
    "        \n",
    "    return X_train, X_test, y_train, y_test, sub_data\n",
    "\n",
    "def cal_score(mse):\n",
    "    if isinstance(mse, float):\n",
    "        return 1 / (1 + math.sqrt(mse))\n",
    "    else:\n",
    "        return np.divide(1, 1 + np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, sub_data = generate_train_data(dup_train_data, test_data, poly=True, select=True)\n",
    "cX_train, cX_test, cy_train, cy_test, _ = generate_train_data(train_data, test_data, poly=True, select=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_X_train = np.concatenate([X_train, X_test])\n",
    "all_y_train = np.concatenate([y_train, y_test])\n",
    "c_all_X_train = np.concatenate([cX_train, cX_test])\n",
    "c_all_y_train = np.concatenate([cy_train, cy_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgbt1 = xgb.XGBRegressor(n_estimators=300, max_depth=3, random_state=2, n_jobs=8)\n",
    "gbdt1 = GradientBoostingRegressor(n_estimators=300, max_depth=3, max_features='log2', random_state=2)\n",
    "forest1 = RandomForestRegressor(n_estimators=100, max_features='log2', random_state=2, n_jobs=8)\n",
    "lgb1 = LGBMRegressor(n_estimators=300, max_depth=3, random_state=2)\n",
    "\n",
    "xgbt2 = xgb.XGBRegressor(n_estimators=200, random_state=3, n_jobs=8)\n",
    "gbdt2 = GradientBoostingRegressor(n_estimators=200, max_features='sqrt', random_state=3)\n",
    "forest2 = RandomForestRegressor(n_estimators=70, max_features='sqrt', random_state=3)\n",
    "lgb2 = LGBMRegressor(n_estimators=200, random_state=3, n_jobs=8)\n",
    "\n",
    "xgbt3 = xgb.XGBRegressor(n_estimators=300, random_state=4, n_jobs=8)\n",
    "gbdt3 = GradientBoostingRegressor(n_estimators=300, max_features='sqrt', random_state=4)\n",
    "forest3 = RandomForestRegressor(n_estimators=150, max_features='sqrt', random_state=4)\n",
    "lgb3 = LGBMRegressor(n_estimators=300, random_state=4, n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "       importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "       min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "       n_estimators=300, n_jobs=8, num_leaves=31, objective=None,\n",
       "       random_state=4, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbt1.fit(all_X_train, all_y_train)\n",
    "gbdt1.fit(all_X_train, all_y_train)\n",
    "forest1.fit(all_X_train, all_y_train)\n",
    "lgb1.fit(all_X_train, all_y_train)\n",
    "\n",
    "xgbt2.fit(all_X_train, all_y_train)\n",
    "gbdt2.fit(all_X_train, all_y_train)\n",
    "forest2.fit(all_X_train, all_y_train)\n",
    "lgb2.fit(all_X_train, all_y_train)\n",
    "\n",
    "xgbt3.fit(c_all_X_train, c_all_y_train)\n",
    "gbdt3.fit(c_all_X_train, c_all_y_train)\n",
    "forest3.fit(c_all_X_train, c_all_y_train)\n",
    "lgb3.fit(c_all_X_train, c_all_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01937677 0.03540199 0.02753378 0.09990208 0.02136231]\n",
      "Average XGB - MSE: 0.04071538665201484  - Score: [0.87780864 0.84164162 0.85768218 0.75983632 0.87247966] \n",
      "\n",
      "[0.02106734 0.0349659  0.0279258  0.09976482 0.02227228]\n",
      "Average XGB - MSE: 0.04119922926004043  - Score: [0.87325116 0.84246586 0.85681716 0.75996175 0.87014101] \n",
      "\n",
      "[0.02715904 0.03592732 0.05523373 0.08671842 0.03033304]\n",
      "Average XGB - MSE: 0.04707430925481936  - Score: [0.85851649 0.84065755 0.80970442 0.77251102 0.8516699 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn1 = KNeighborsRegressor(n_neighbors=5)\n",
    "knn1.fit(all_X_train, all_y_train)\n",
    "scores_knn = cross_val_score(knn, all_X_train, all_y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "print(-scores_knn)\n",
    "knn_avg = np.average(-scores_knn)\n",
    "print('Average XGB - MSE:', knn_avg, ' - Score:', cal_score(-scores_knn), '\\n')\n",
    "\n",
    "knn2 = KNeighborsRegressor(n_neighbors=4)\n",
    "knn2.fit(all_X_train, all_y_train)\n",
    "scores_knn2 = cross_val_score(knn2, all_X_train, all_y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "print(-scores_knn2)\n",
    "knn_avg2 = np.average(-scores_knn2)\n",
    "print('Average XGB - MSE:', knn_avg2, ' - Score:', cal_score(-scores_knn2), '\\n')\n",
    "\n",
    "knn3 = KNeighborsRegressor(n_neighbors=4)\n",
    "knn3.fit(c_all_X_train, c_all_y_train)\n",
    "scores_knn3 = cross_val_score(knn3, c_all_X_train, c_all_y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "print(-scores_knn3)\n",
    "knn_avg3 = np.average(-scores_knn3)\n",
    "print('Average XGB - MSE:', knn_avg3, ' - Score:', cal_score(-scores_knn3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "regrs = [\n",
    "    xgbt1, xgbt2, xgbt3,\n",
    "    gbdt1, gbdt2, gbdt3,\n",
    "    forest1, forest2, forest3,\n",
    "    knn1, knn2, knn3\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Stacker(object):\n",
    "    def __init__(self, n_splits, stacker, base_models):\n",
    "        self.n_splits = n_splits\n",
    "        self.stacker = stacker\n",
    "        self.base_models = base_models\n",
    "    \n",
    "    # X: 原始训练集, y: 原始训练集真实值, predict_data: 原始待预测数据\n",
    "    def fit_predict(self, X, y, predict_data):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        T = np.array(predict_data)\n",
    "\n",
    "        folds = list(KFold(n_splits=self.n_splits, shuffle=False, random_state=2018).split(X, y))\n",
    "        \n",
    "        # 以基学习器预测结果为特征的 stacker的训练数据 与 stacker预测数据\n",
    "        S_train = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        S_predict = np.zeros((predict_data.shape[0], len(self.base_models)))\n",
    "        \n",
    "        for i, regr in enumerate(self.base_models):\n",
    "            print('Base model:', str(regr).split('(')[0])\n",
    "            S_predict_i = np.zeros((predict_data.shape[0], self.n_splits))\n",
    "            \n",
    "            for j, (train_idx, test_idx) in enumerate(folds):\n",
    "                # 将X分为训练集与测试集\n",
    "                X_train, y_train, X_test, y_test = X[train_idx], y[train_idx], X[test_idx], y[test_idx]\n",
    "                print ('Fit fold', (j+1), '...')\n",
    "                regr.fit(X_train, y_train)\n",
    "                y_pred = regr.predict(X_test)                \n",
    "                S_train[test_idx, i] = y_pred\n",
    "                S_predict_i[:, j] = regr.predict(T)\n",
    "            \n",
    "            S_predict[:, i] = S_predict_i.mean(axis=1)\n",
    "\n",
    "        nmse_score = cross_val_score(self.stacker, S_train, y, cv=5, scoring='neg_mean_squared_error')\n",
    "        print('CV MSE:', -nmse_score)\n",
    "        print('Stacker AVG MSE:', -nmse_score.mean(), 'Stacker AVG Score:', np.mean(np.divide(1, 1 + np.sqrt(-nmse_score))))\n",
    "\n",
    "        self.stacker.fit(S_train, y)\n",
    "        res = self.stacker.predict(S_predict)\n",
    "        return res, S_train, S_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stacking_model = Ridge(alpha=0.387, copy_X=True, fit_intercept=False, solver='auto', random_state=2)\n",
    "stacker = Stacker(5, stacking_model, regrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model: XGBRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "Base model: XGBRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "Base model: XGBRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "Base model: GradientBoostingRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "Base model: GradientBoostingRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "Base model: GradientBoostingRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "Base model: RandomForestRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "Base model: RandomForestRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "Base model: RandomForestRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "Base model: KNeighborsRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "Base model: KNeighborsRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "Base model: KNeighborsRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "CV MSE: [0.0107378  0.01996252 0.01105789 0.08448941 0.01448108]\n",
      "Stacker AVG MSE: 0.028145738864851038 Stacker AVG Score: 0.870907438135179\n"
     ]
    }
   ],
   "source": [
    "pred_stack, S_train_data, S_predict_data = stacker.fit_predict(all_X_train, all_y_train, sub_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_result['score'] = pred_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = df_result[df_result['ID'].isin(special_missing_ID)].index\n",
    "df_result.loc[index, 'score'] = 0.379993053\n",
    "df_result[df_result['ID'].isin(special_missing_ID)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_result.to_csv('submit_stack_15_poly_select_dropdup_outlier.csv', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
